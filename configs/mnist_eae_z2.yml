logdir: 'results/MNIST/DIM_2/'
logger: 
  type: base
  endwith: ['@']
model:
  arch: eae 
  # encoder:
  #   arch: fc_image
  #   l_hidden: [256, 256, 256, 256, ]
  #   activation: ['relu', 'relu', 'relu', 'relu', ]
  #   out_activation: 'linear'
  #   img_size: [1, 28, 28]
  #   out_chan_num: 1
  # decoder:
  #   arch: fc_image
  #   l_hidden: [256, 256, 256, 256, ]
  #   activation: ['relu', 'relu', 'relu', 'relu', ]
  #   out_activation: 'sigmoid'
  #   img_size: [1, 28, 28]
  #   out_chan_num: 1
  encoder: 
    arch: conv2fc 
    nh: 8
    nh_mlp: 1024
    out_activation: linear 
  decoder:
    arch: deconv2
    nh: 8
    out_activation: sigmoid 
  energy:
    n_layers: 2
  sigma:
    n_layers: 2
  # energy:
  #   arch: fc_image
  #   l_hidden: [1024, 1024, 1024, 1024, 1024] # [256, 256, 256, 256]
  #   activation: ['relu', 'relu', 'relu', 'relu', 'relu']
  #   out_activation: 'linear'
  #   out_chan_num: 1
  # sigma:
  #   arch: fc_image
  #   l_hidden: [1024, 1024, 1024, 1024, 1024] # [256, 256, 256, 256, 256]
  #   activation: ['relu', 'relu', 'relu', 'relu' , 'relu' ]
  #   out_activation: 'sigmoid'
  #   out_chan_num: 1
  x_dim: 1
  z_dim: 15
  min_sigma_sq: 1e-5
  max_sigma_sq: 1e-1
  energy_ae:
    sigma_sq: 1e-2
    harmonic_pretrain: false
    energy_detach: True
    harmonic_detach: True
    conformal_detach: false
    train_sigma: True
  ebm:
    gamma: 0.001
    temperature: 0.01
    step_size: 1e-8
    noise_scale: null
    sample_step: 30
    buffer_size: 10000
    replay_ratio: 0.95
    langevin_clip_grad: Null
data:
  training:
    dataset: MNIST
    root: dataset
    batch_size: 256
    n_workers: 4
    split: training
    shuffle: True
    digits: [0, 1, 2, 4, 5, 6, 7, 8, 9]
  validation:
    dataset: MNIST
    root: dataset
    batch_size: 256
    n_workers: 4
    split: validation
    shuffle: False
    digits: [0, 1, 2, 4, 5, 6, 7, 8, 9]
  test:
    dataset: MNIST
    root: dataset
    batch_size: 256
    n_workers: 4
    split: test
    shuffle: False
    digits: [0, 1, 2, 4, 5, 6, 7, 8, 9]
  OOD_validation:
    dataset: MNIST
    root: dataset
    batch_size: 256
    n_workers: 4
    split: validation
    shuffle: False
    digits: [3]
  OOD_test:
    dataset: MNIST
    root: dataset
    batch_size: 256
    n_workers: 4
    split: test
    shuffle: False
    digits: [3]
  
trainer: base
training:
  n_epoch: 200
  n_epoch_pre: 30
  n_epoch_ebm: 10
  fix_decoder: False
  optimizer_pre:
    name: 'adam'
    lr: 1e-4
  optimizer:
    lr_encoder: 1e-4
    lr_encoder_pre: 1e-4
    lr_decoder: 1e-4
    lr_energy: 3e-5
    lr_sigma: 1e-5
  print_interval: 200
  val_interval: 200
  visualize_interval: 200

 